Infraestructura
---------------
----------------


Docker
---------

Cada proyecto tendr√° su propio directorio con un archivo docker-compose.yml:



‚îú‚îÄ‚îÄ bigdata-proyecto-smartcity/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml  # FIWARE, CrateDB, Grafana
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ sensors_data.json
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ simulation_script.py
‚îú‚îÄ‚îÄ bigdata-proyecto-academico/
‚îÇ   ‚îú‚îÄ‚îÄ docker-compose.yml  # Base de Datos (PostgreSQL/MySQL), Herramienta ETL
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ calificaciones.csv
‚îÇ   ‚îî‚îÄ‚îÄ src/
‚îÇ       ‚îî‚îÄ‚îÄ etl_script.py
‚îî‚îÄ‚îÄ README.md



. Comandos Esenciales de Docker
Acci√≥n	Comando	Notas
Arrancar Infraestructura	docker-compose up -d	Levanta todos los servicios en segundo plano.
Ver Logs	docker-compose logs -f	Monitorea la actividad de todos los servicios.
Detener Infraestructura	docker-compose down	Detiene y elimina los contenedores (conserva las im√°genes).
Ejecutar Script	docker exec -it <nombre_contenedor> python src/script.py	Ejecuta tu c√≥digo (simulaci√≥n, ETL) dentro de un contenedor.

Flujo de Trabajo con Git
----------------------------


El flujo de trabajo debe ser constante y descriptivo. Un buen historial de commits demuestra c√≥mo avanzaste en el proyecto:

Trabajo Inicial (Infraestructura):


git add docker-compose.yml
git commit -m "feat: Inicializar infraestructura Docker con Orion, CrateDB y Grafana"
git push origin main
Desarrollo (Fase 1 - Entidades y Simulaci√≥n):


git add src/simulation_script.py
git commit -m "feat: Implementar simulaci√≥n de los tres sensores (Temp, CO2, Agua) y enviar a Orion"
git push origin main
Documentaci√≥n (Fase 2 - ETL):


git add src/etl_process.py
git commit -m "refactor: Crear proceso ETL para calcular valores Max/Min/Medios diarios y cargar en Data Warehouse"
git push origin main


README.md: La Documentaci√≥n Esencial

README.md es tu informe final  y debe estar en la ra√≠z de tu repositorio. No solo debe describir el proyecto, sino tambi√©n servir de gu√≠a de ejecuci√≥n para el evaluador.

Secci√≥n del README.md	Contenido M√≠nimo (Ej. Proyecto Acad√©mico)
1. Definici√≥n del Proyecto Objetivo (Consolidar hist√≥ricos e indicadores de calidad ) y enfoque (Modelo dimensional para BI ).
2. Infraestructura T√©cnica Lista de contenedores ( PostgreSQL o MySQL para Data Warehouse, Python/Pandas en contenedor para el ETL). Incluir la estructura del docker-compose.yml.
3. Proceso ETL y Modelo de Datos Diagrama o descripci√≥n de c√≥mo se transforman los archivos CSV (ITACA, PAA)  en tablas de Hechos y Dimensiones. Describir las validaciones realizadas.

4. Instrucciones de Uso	Pasos exactos: git clone, docker-compose up -d, c√≥mo ejecutar el script ETL (python src/etl_process.py), y c√≥mo conectar Power BI al Data Warehouse.
5. Resultados (Power BI) Capturas de pantalla del Cuadro de Mando , mostrando el porcentaje de aprobaci√≥n y los filtros aplicables (Familia, Curso, Evaluaci√≥n, etc.).












AWS:
-----

-Bases de Datos
-Almacenamiento en S3
















- docker-compose Proyecto Smart City   BD:  AWS
- docker-compose Nifi                  BD: AWS
- docker compose Airflow               BD:  Aws

------------------------------




# üìö Apuntes de Infraestructura y Flujo de Trabajo

## üèóÔ∏è Infraestructura con Docker

La infraestructura de cada proyecto se gestiona mediante **Docker Compose**, asegurando que cada entorno sea aislado y reproducible.

### üìÇ Estructura de Directorios (Ejemplos)

Cada proyecto reside en su propio directorio y contiene un archivo `docker-compose.yml` para definir sus servicios.

| Proyecto | Archivos Clave | Servicios T√≠picos |
| :--- | :--- | :--- |
| `bigdata-proyecto-smartcity/` | `docker-compose.yml` | **FIWARE** (Orion Context Broker), **CrateDB**, **Grafana** |
| | `data/sensors_data.json` | |
| | `src/simulation_script.py` | |
| `bigdata-proyecto-academico/` | `docker-compose.yml` | Base de Datos (**PostgreSQL** o **MySQL**), Herramienta **ETL** (Contenedor Python) |
| | `data/calificaciones.csv` | |
| | `src/etl_script.py` | |

---

### ‚öôÔ∏è Comandos Esenciales de Docker Compose

| Acci√≥n | Comando | Notas |
| :--- | :--- | :--- |
| **Arrancar** Infraestructura | `docker-compose up -d` | Levanta todos los servicios en **segundo plano**. |
| **Ver Logs** | `docker-compose logs -f` | Monitorea la actividad en tiempo real de todos los servicios. |
| **Detener** Infraestructura | `docker-compose down` | Detiene y **elimina los contenedores** (conserva las im√°genes). |
| **Ejecutar Script** | `docker exec -it <nombre_contenedor> python src/script.py` | Ejecuta tu c√≥digo (simulaci√≥n, ETL) **dentro de un contenedor** existente. |

---

## üíæ Flujo de Trabajo con Git

El historial de `commits` debe ser **constante y descriptivo** para mostrar el progreso. Se recomienda seguir un esquema de mensajes claro.

| Etapa | Comando `git` | Mensaje de Commit (Ejemplo) | Prop√≥sito |
| :--- | :--- | :--- | :--- |
| **Infraestructura** | `git add docker-compose.yml` | `feat: Inicializar infraestructura Docker con Orion, CrateDB y Grafana` | Establecer el entorno de trabajo. |
| **Desarrollo** | `git add src/simulation_script.py` | `feat: Implementar simulaci√≥n de los tres sensores (Temp, CO2, Agua) y enviar a Orion` | Implementaci√≥n de nueva funcionalidad. |
| **Documentaci√≥n/Refactor** | `git add src/etl_process.py` | `refactor: Crear proceso ETL para calcular valores Max/Min/Medios diarios y cargar en Data Warehouse` | Mejora o reestructuraci√≥n de c√≥digo/procesos. |

**Recordatorio:** Despu√©s de cada `commit`, ejecuta `git push origin main` para sincronizar con el repositorio remoto.

---

## üìÑ README.md: La Documentaci√≥n Esencial

El archivo `README.md` es el **informe final** y la **gu√≠a de ejecuci√≥n** del proyecto. Debe estar en la ra√≠z del repositorio.

| Secci√≥n del README.md | Contenido M√≠nimo Requerido (Ej. Proyecto Acad√©mico) |
| :--- | :--- |
| 1. **Definici√≥n del Proyecto** | **Objetivo** (Ej: Consolidar hist√≥ricos e indicadores de calidad) y **enfoque** (Ej: Modelo dimensional para BI). |
| 2. **Infraestructura T√©cnica** | Lista de **contenedores** (PostgreSQL/MySQL, Contenedor Python para ETL). Incluir la estructura del `docker-compose.yml`. |
| 3. **Proceso ETL y Modelo de Datos** | **Diagrama o descripci√≥n** de la transformaci√≥n de archivos CSV (ITACA, PAA) en tablas de Hechos y Dimensiones. Describir las **validaciones** realizadas. |
| 4. **Instrucciones de Uso** | Pasos **exactos** para la ejecuci√≥n: `git clone`, `docker-compose up -d`, c√≥mo ejecutar el script ETL (`python src/etl_process.py`), y c√≥mo conectar la herramienta de BI (Ej: Power BI) al Data Warehouse. |
| 5. **Resultados (Power BI)** | **Capturas de pantalla** del Cuadro de Mando, mostrando indicadores clave (Ej: porcentaje de aprobaci√≥n) y filtros aplicables (Familia, Curso, Evaluaci√≥n, etc.). |

---

## ‚òÅÔ∏è Referencia a AWS

La infraestructura podr√≠a incorporar servicios en la nube de **AWS** para:

* **Bases de Datos:** Uso de servicios gestionados de bases de datos (Ej: Amazon RDS).
* **Almacenamiento:** Uso de **S3** (Simple Storage Service) para archivos est√°ticos o *data lakes*.


2 Laboratorios 1 por evaluaci√≥n



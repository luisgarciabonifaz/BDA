춰Excelente! Continuamos con el desarrollo del curso. Aqu칤 tienes la propuesta de apuntes para el **M칩dulo 2**, siguiendo el mismo formato did치ctico y pr치ctico.

------



## **Apuntes de Clase: M칩dulo 2 - Python para Data Engineering**





### **Introducci칩n al M칩dulo**



Si el Big Data fuera una gran obra de construcci칩n, Python ser칤a la navaja suiza que todo ingeniero lleva en su cintur칩n. Es el lenguaje que nos permite automatizar tareas, conectar sistemas que no hablan entre s칤, y lo m치s importante: **manipular y limpiar los datos**. Un ingeniero de datos pasa entre el 60% y el 80% de su tiempo en tareas de limpieza y preparaci칩n de datos. Dominar las herramientas para hacerlo eficientemente es, por tanto, una habilidad crucial.

En este m칩dulo, nos sumergiremos en **Pandas**, la librer칤a que ha convertido a Python en el rey del an치lisis de datos. Aprenderemos a cargar, inspeccionar, limpiar y transformar datos tabulares. Al final, aplicaremos estos conocimientos para dar los primeros pasos pr치cticos en nuestros dos proyectos: pondremos orden en los datos acad칠micos y construiremos un simulador para los sensores de nuestra Smart City. 춰Vamos a ensuciarnos las manos con c칩digo!

------



### **2.1. Python como Lenguaje Vehicular: 쯇or qu칠 Python?**



Python no es el 칰nico lenguaje de programaci칩n, pero es el dominante en el mundo de los datos por varias razones clave:

- **Sintaxis Sencilla y Legible:** Su c칩digo se parece mucho al ingl칠s, lo que facilita su aprendizaje y permite escribir programas de forma r치pida y clara.
- **Ecosistema de Librer칤as Gigante:** La verdadera magia de Python reside en sus librer칤as especializadas. Para datos, tenemos:
  - **Pandas:** Para manipulaci칩n de datos tabulares (nuestro foco principal).
  - **NumPy:** Para c치lculo num칠rico y operaciones matem치ticas eficientes.
  - **Requests:** Para comunicarnos con APIs y obtener datos de la web.
  - Y muchas m치s (Scikit-learn para Machine Learning, Matplotlib para visualizaci칩n, etc.).
- **Gran Comunidad y Soporte:** Si tienes un problema, es casi seguro que alguien ya lo ha tenido y hay una soluci칩n en internet (en foros como Stack Overflow, por ejemplo).
- **Integraci칩n ("Glue Language"):** Python es conocido como un "lenguaje pegamento" porque puede conectar f치cilmente diferentes tecnolog칤as: bases de datos, servicios en la nube, APIs, etc.

Nuestro Entorno de Trabajo: Jupyter Notebooks

Para este m칩dulo, usaremos Jupyter Notebooks (o un entorno similar como VS Code con la extensi칩n de Python). Son herramientas interactivas que nos permiten ejecutar c칩digo en celdas individuales y ver el resultado inmediatamente, mezclando c칩digo, texto y gr치ficos. Son el est치ndar de facto para la exploraci칩n y el an치lisis de datos.

------



### **2.2. Librer칤a Pandas: El Coraz칩n del An치lisis de Datos 游냪**



Pandas es una librer칤a que nos proporciona estructuras de datos y herramientas para trabajar con datos tabulares (como los de un fichero CSV o una tabla de SQL) de una forma muy intuitiva y potente. 춰Es como tener superpoderes en Excel!



#### **Estructuras de Datos Fundamentales**



- **`Series`**: Es un array de una dimensi칩n, similar a una 칰nica columna de una tabla. Cada elemento tiene un 칤ndice asociado.

  Python

  ```
  import pandas as pd
  
  # Una Serie de notas
  notas = pd.Series([7, 5, 9, 10], index=['Mates', 'Lengua', 'Ingl칠s', 'Historia'])
  print(notas)
  ```

- **`DataFrame`**: Es una tabla de dos dimensiones (filas y columnas). Es la estructura de datos m치s importante y la que usaremos constantemente. Podemos pensar en ella como una colecci칩n de `Series`.

  Python

  ```
  # Un DataFrame de alumnos
  datos_alumnos = {
      'nombre': ['Ana', 'Juan', 'Eva'],
      'edad': [22, 25, 23],
      'ciudad': ['Valencia', 'Madrid', 'Valencia']
  }
  df_alumnos = pd.DataFrame(datos_alumnos)
  print(df_alumnos)
  ```



#### **El 칈ndice: La Columna Vertebral de Pandas**



El 칤ndice es uno de los conceptos m치s potentes de Pandas. No es solo un n칰mero de fila; es una etiqueta que permite una alineaci칩n de datos incre칤blemente r치pida y un acceso eficiente. Aunque no lo modifiquemos, siempre est치 ah칤. M치s adelante, aprenderemos a establecer nuestras propias columnas como 칤ndice (por ejemplo, una columna de fecha) para realizar an치lisis de series temporales de forma muy eficiente.

#### **Operaciones Fundamentales: El Flujo de Trabajo del Analista**



1. Carga de Datos

   El primer paso es siempre leer los datos desde una fuente. La funci칩n m치s com칰n es pd.read_csv().

   Python

   ```
   # Ejemplo de carga de datos m치s robusta
   df = pd.read_csv(
       'datos/fichero_complejo.csv',
       sep=';',                  # Separador de columnas
       decimal=',',              # Caracter usado para los decimales
       encoding='utf-8',         # Codificaci칩n del fichero para evitar errores con tildes o caracteres especiales
       dtype={'id_cliente': str} # Forzar que una columna se lea como texto (muy 칰til para IDs que parecen n칰meros pero no lo son)
   )
   ```

2. Diagn칩stico y Exploraci칩n Profunda

   Una vez cargados los datos, nunca asumimos que est치n bien. Hacemos una revisi칩n r치pida:

   Python

   ```
   # Ver las 5 primeras filas
   print(df_notas.head())
   
   # Ver un resumen t칠cnico: columnas, tipos de datos, valores no nulos
   print(df_notas.info())
   
   # Ver un resumen estad칤stico de las columnas num칠ricas
   print(df_notas.describe())
   
   # Ver el n칰mero de filas y columnas (forma del DataFrame)
   print(df_notas.shape)
   ```

   Antes de cambiar nada, hay que ser un buen detective.

   - `df.info(verbose=True)`: Nos da un resumen completo. Debemos fijarnos en:
     - **Dtype (Tipo de dato):** 쯋na columna que deber칤a ser num칠rica aparece como `object`? Esto indica que hay valores de texto mezclados que debemos limpiar.
     - **Non-Null Count (Conteo de no nulos):** 쮺oincide con el n칰mero total de filas? Si no, ya sabemos que tenemos valores nulos que tratar.
   - `df.value_counts('nombre_columna')`: Es una de las herramientas de diagn칩stico m치s 칰tiles. Nos muestra la frecuencia de cada valor en una columna. Es perfecta para detectar:
     - Errores tipogr치ficos (ej. "Valencia", "valencia", "Valensia").
     - Valores inesperados en columnas categ칩ricas.

   Python

   ```
   # Ejemplo de uso de value_counts para la columna 'Turno' del Proyecto 2
   print(df_alumnos['Turno'].value_counts())
   # Output esperado:
   # Diurno           500
   # Semipresencial   150
   # Name: Turno, dtype: int64
   
   # Si vi칠ramos "diurno" en min칰sculas, ya habr칤amos detectado un problema de consistencia.
   ```

   

3. **Selecci칩n y Filtrado (Acceder a lo que nos interesa)**

   - **Seleccionar Columnas:**

     Python

     ```
     # Seleccionar una columna (devuelve una Serie)
     nombres = df_alumnos['nombre']
     
     # Seleccionar varias columnas (devuelve un DataFrame)
     nombre_y_edad = df_alumnos[['nombre', 'edad']]
     ```

   - **Filtrar Filas por Condici칩n:**

     Python

     ```
     # Filtrar alumnos de Valencia
     alumnos_valencia = df_alumnos[df_alumnos['ciudad'] == 'Valencia']
     
     # Filtrar alumnos mayores de 22 a침os
     mayores_de_22 = df_alumnos[df_alumnos['edad'] > 22]
     
     # Combinar condiciones (& para 'Y', | para 'O')
     ana_o_eva = df_alumnos[(df_alumnos['nombre'] == 'Ana') | (df_alumnos['nombre'] == 'Eva')]
     ```

4. **Limpieza de Datos (El pan de cada d칤a)**

   - **Manejo de Valores Nulos (`NaN`):**

     Python

     ```
     # Contar cu치ntos valores nulos hay en cada columna
     print(df_notas.isnull().sum())
     
     # Opci칩n 1: Eliminar las filas que tengan alg칰n valor nulo
     df_sin_nulos = df_notas.dropna()
     
     # Opci칩n 2: Rellenar los nulos con un valor (ej. 0 para las notas)
     df_notas_relleno = df_notas.fillna(value={'nota': 0})
     ```

   - Correcci칩n de Tipos de Datos:

     A veces, un n칰mero se lee como texto. Con astype() lo corregimos.

     Python

     ```
     # Imagina que la columna 'id_alumno' se lee como texto
     df_notas['id_alumno'] = df_notas['id_alumno'].astype(int)
     ```

   - **Crear y Modificar Columnas:**

     Python

     ```
     # Crear una nueva columna
     df_alumnos['a침o_nacimiento'] = 2025 - df_alumnos['edad']
     ```

   - Guardar el resultado:

     Tras la limpieza, guardamos el resultado en un nuevo fichero.

     Python

     ```
     # Guardamos el DataFrame limpio. index=False evita que se guarde el 칤ndice de Pandas como una columna.
     df_notas_relleno.to_csv('datos/calificaciones_limpio.csv', index=False)
     ```

------

- **Eliminar Duplicados:**

  Python

  ```
  # Muestra el n칰mero de filas antes de eliminar duplicados
  print(f"Filas antes: {len(df)}")
  df_sin_duplicados = df.drop_duplicates()
  print(f"Filas despu칠s: {len(df_sin_duplicados)}")
  ```

- **Estrategias de `fillna`:**

  Python

  ```
  # Rellenar con un valor est치tico
  df['columna'].fillna(0)
  
  # Rellenar con el valor anterior o posterior (칰til en series de tiempo)
  df['columna'].fillna(method='ffill') # Forward fill
  
  # Rellenar con la media de la columna (muy com칰n)
  media = df['columna_numerica'].mean()
  df['columna_numerica'].fillna(media)
  ```

- **Manipulaci칩n de Texto (`.str`):** El accesor `.str` nos da acceso a decenas de funciones para trabajar con texto.

  Python

  ```
  # Poner en min칰sculas
  df['nombre'] = df['nombre'].str.lower()
  
  # Eliminar espacios en blanco al principio y al final
  df['nombre'] = df['nombre'].str.strip()
  
  # Reemplazar texto
  df['curso'] = df['curso'].str.replace('1췈', 'Primero')
  
  # Extraer patrones con expresiones regulares (regex)
  # Imagina una columna 'codigo' con formato 'LETTERS-NUMBERS' (ej. 'DAM-101')
  df['numero_codigo'] = df['codigo'].str.extract(r'-(\d+)')
  ```

------



### 

### **2.3. Conexi칩n a Fuentes de Datos (M치s all치 del CSV)**



- **JSON (JavaScript Object Notation):** Es un formato de texto ligero para el intercambio de datos, muy usado en APIs web. Es como un diccionario de Python.

  Python

  ```
  import json
  
  # Guardar un diccionario a un fichero JSON
  mi_diccionario = {'nombre': 'sensor01', 'valor': 25}
  with open('sensor.json', 'w') as f:
      json.dump(mi_diccionario, f)
  ```

- #### **Manejando la Complejidad de JSON con `json_normalize`**

  Los datos de APIs a menudo vienen en formato JSON anidado (diccionarios dentro de diccionarios). Pandas tiene una funci칩n m치gica para "aplanar" estos datos y convertirlos en una tabla.

  Python

  ```
  # Ejemplo de JSON anidado
  data = [{'id': 1, 'nombre': 'Ana', 'direccion': {'calle': 'Mayor', 'numero': 10}},
          {'id': 2, 'nombre': 'Juan', 'direccion': {'calle': 'Sol', 'numero': 5}}]
  
  # Sin normalizar, la columna 'direccion' ser칤a un diccionario, lo cual es dif칤cil de usar.
  # df = pd.DataFrame(data)
  
  # Usando json_normalize
  df_normalizado = pd.json_normalize(data)
  print(df_normalizado)
  # Output:
  #    id nombre direccion.calle  direccion.numero
  # 0   1    Ana           Mayor                10
  # 1   2   Juan             Sol                 5
  ```

  

  #### 

- **APIs (Application Programming Interfaces):** Son "enchufes" que exponen los sistemas para que otros programas puedan conectarse y obtener datos de forma controlada. Usaremos la librer칤a `requests` para "llamar" a estas APIs.

  Python

  ```
  import requests
  
  # Ejemplo: Llamar a una API que nos da datos del tiempo en Valencia
  # (Esto es un ejemplo, la URL puede no funcionar siempre)
  response = requests.get('https://goweather.herokuapp.com/weather/Valencia')
  
  # Convertir la respuesta JSON a un diccionario de Python
  datos_tiempo = response.json()
  print(datos_tiempo)
  ```

------

#### **Interactuando con APIs de Forma Segura**



Cuando llamamos a una API con `requests.get()`, la respuesta contiene un **c칩digo de estado** que nos dice si todo fue bien.

- `200 OK`: 춰칄xito! La petici칩n se complet칩 correctamente.
- `404 Not Found`: El recurso que pediste no existe.
- `403 Forbidden` / `401 Unauthorized`: No tienes permisos para acceder.
- `500 Internal Server Error`: Hubo un problema en el servidor de la API.

Es una buena pr치ctica comprobar siempre el c칩digo de estado antes de intentar usar los datos.

Python

```
response = requests.get('https://api.example.com/data')

if response.status_code == 200:
    data = response.json()
    print("Datos obtenidos con 칠xito.")
else:
    print(f"Error al llamar a la API: C칩digo {response.status_code}")
```



### **2.4. Pr치ctica: Construyendo Nuestros Scripts 游눹**



#### **Pr치ctica 1 (Proyecto 2): Limpieza Inicial de Datos Acad칠micos**



**Objetivo:** Aplicar el flujo de trabajo de Pandas para hacer una primera limpieza de uno de los ficheros CSV del proyecto acad칠mico.

Python

```
# Fichero: limpiar_calificaciones.py

import pandas as pd

# 1. CARGA DE DATOS
print("Cargando datos de calificaciones...")
# Asumimos que el separador es ';' y que algunos n칰meros pueden tener ',' como decimal
df = pd.read_csv('datos_proyecto/Calificaciones.csv', sep=';', decimal=',')

# 2. INSPECCI칍N INICIAL
print("--- Informaci칩n Inicial del DataFrame ---")
df.info()
print("\n--- Valores Nulos por Columna ---")
print(df.isnull().sum())

# 3. LIMPIEZA
print("\nIniciando limpieza...")
# Rellenamos las calificaciones nulas con 0, asumiendo que un nulo es un no presentado
df['Calificacion'] = df['Calificacion'].fillna(0)

# Convertimos la columna de calificaci칩n a tipo num칠rico (float)
df['Calificacion'] = df['Calificacion'].astype(float)

# Convertimos la columna de fecha a tipo datetime
df['Fecha'] = pd.to_datetime(df['Fecha'], dayfirst=True)

# 4. VERIFICACI칍N FINAL
print("\n--- Informaci칩n Final del DataFrame ---")
df.info()
print("\n--- Valores Nulos Restantes ---")
print(df.isnull().sum())
print("\nLimpieza completada.")

# 5. GUARDADO
output_path = 'datos_procesados/Calificaciones_limpio.csv'
print(f"Guardando fichero limpio en: {output_path}")
df.to_csv(output_path, index=False, sep=';')
```

#### **Limpieza Detallada de Datos Acad칠micos**



Python

```
# Fichero: limpiar_calificaciones_detallado.py
import pandas as pd

# --- PASO 1: CARGA DE DATOS ---
# Se utiliza un bloque try-except para manejar el error si el fichero no se encuentra.
try:
    df = pd.read_csv('datos_proyecto/Calificaciones.csv', sep=';', decimal=',')
except FileNotFoundError:
    print("Error: El fichero 'Calificaciones.csv' no se encontr칩. Verifica la ruta.")
    exit()

# --- PASO 2: DIAGN칍STICO ---
# Una buena pr치ctica es imprimir la forma del DataFrame para saber con cu치ntos datos empezamos.
print(f"El fichero tiene {df.shape[0]} filas y {df.shape[1]} columnas.")
# .info() nos da el mapa de nuestros datos: tipos y nulos.
df.info()

# --- PASO 3: LIMPIEZA Y TRANSFORMACI칍N ---
# Columna 'Calificacion': Los nulos pueden significar "No Presentado". Llenarlos con 0 es una decisi칩n de negocio.
df['Calificacion'] = df['Calificacion'].fillna(0)
# Aseguramos que la columna es de tipo num칠rico para poder hacer c치lculos con ella.
df['Calificacion'] = df['Calificacion'].astype(float)

# Columna 'Fecha': Convertir texto a un objeto de fecha real nos permite hacer an치lisis temporales.
# 'dayfirst=True' le dice a Pandas que el formato es DD/MM/AAAA.
df['Fecha'] = pd.to_datetime(df['Fecha'], dayfirst=True, errors='coerce')
# 'errors='coerce'' convertir치 cualquier fecha con formato incorrecto en 'NaT' (Not a Time), que podremos detectar.

# --- PASO 4: CREACI칍N DE NUEVAS COLUMNAS (Enriquecimiento) ---
# Vamos a crear una columna categ칩rica 'Estado' para simplificar el an치lisis futuro.
# Aqu칤 usamos una funci칩n lambda, una forma compacta de definir una funci칩n.
df['Estado'] = df['Calificacion'].apply(lambda nota: 'Aprobado' if nota >= 5 else 'Suspenso')

# --- PASO 5: VERIFICACI칍N FINAL ---
print("\n--- DataFrame despu칠s de la limpieza y enriquecimiento ---")
print(df.head())
print("\nTipos de datos finales:")
df.info()

# --- PASO 6: GUARDADO ---
# Guardar el resultado en un nuevo fichero es crucial para no sobrescribir los datos originales.
output_path = 'datos_procesados/Calificaciones_limpio.csv'
df.to_csv(output_path, index=False, sep=';', decimal=',')
print(f"\nProceso completado. Fichero limpio guardado en: {output_path}")
```

#### **Pr치ctica 2 (Proyecto 1): Simulador de Sensores de la Smart City**



**Objetivo:** Crear un script de Python que genere datos de sensores simulados y los guarde en un fichero JSON, listos para ser ingeridos en el siguiente m칩dulo.

Python

```
# Fichero: generar_datos_sensores.py

import json
import random
from datetime import datetime, timedelta

# 1. CONFIGURACI칍N
SENSOR_IDS = {
    "temp_hum": "urn:ngsi-ld:TemperatureSensor:001",
    "co2": "urn:ngsi-ld:CO2Sensor:001",
    "agua": "urn:ngsi-ld:WaterQualitySensor:001"
}
FECHA_INICIO = datetime(2025, 3, 1)
NUM_DIAS = 61 # Marzo y Abril
LECTURAS_POR_DIA = round(400 / NUM_DIAS)

# 2. FUNCI칍N PARA GENERAR UNA LECTURA
def crear_lectura_sensor(sensor_id, timestamp):
    lectura = {
        "id": sensor_id,
        "timestamp": timestamp.isoformat() # Formato est치ndar ISO 8601
    }
    if sensor_id == SENSOR_IDS["temp_hum"]:
        lectura["type"] = "TemperatureSensor"
        lectura["temperature"] = round(random.uniform(15.0, 30.0), 2)
        lectura["humidity"] = round(random.uniform(40.0, 75.0), 2)
    elif sensor_id == SENSOR_IDS["co2"]:
        lectura["type"] = "CO2Sensor"
        lectura["co2"] = random.randint(400, 1200) # en ppm
    elif sensor_id == SENSOR_IDS["agua"]:
        lectura["type"] = "WaterQualitySensor"
        lectura["ph"] = round(random.uniform(6.5, 8.5), 2)
        lectura["temperature"] = round(random.uniform(12.0, 22.0), 2)
        lectura["chlorine"] = round(random.uniform(0.5, 1.5), 3)
    return lectura

# 3. BUCLE DE GENERACI칍N
print("Generando datos simulados para los sensores...")
datos_generados = []
current_date = FECHA_INICIO

for _ in range(NUM_DIAS * LECTURAS_POR_DIA):
    # Generamos una lectura para cada tipo de sensor en un momento aleatorio del d칤a
    for sensor_key, sensor_id in SENSOR_IDS.items():
        # A침adimos una variaci칩n aleatoria de tiempo para que no sean todas a la vez
        random_seconds = random.randint(0, 86400) # Segundos en un d칤a
        timestamp = FECHA_INICIO + timedelta(seconds=random_seconds + (_ * 86400 / LECTURAS_POR_DIA))
        if timestamp < FECHA_INICIO + timedelta(days=NUM_DIAS):
            datos_generados.append(crear_lectura_sensor(sensor_id, timestamp))

# 4. GUARDADO EN FICHERO JSON
output_path = 'datos_generados/sensor_data.json'
print(f"Generadas {len(datos_generados)} lecturas.")
print(f"Guardando datos en: {output_path}")

with open(output_path, 'w') as f:
    json.dump(datos_generados, f, indent=4)

print("춰Proceso completado!")
```